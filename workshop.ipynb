{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¤– Building a Robust Computer Vision Model! ðŸ§ \n",
                "\n",
                "Welcome! In this workshop, you'll take the model you trained on Teachable Machine and make it even smarter and more robust.\n",
                "\n",
                "**Our Journey:**\n",
                "1.  **Upload & Setup:** We'll get our environment ready and upload the model and image samples you created.\n",
                "2.  **Sanity Check:** We'll test your original model on your original images to make sure it works. \n",
                "3.  **The Break Test:** We'll try to \"trick\" your model with rotated and noisy images to see its weaknesses.\n",
                "4.  **The Training Montage:** We'll teach your model to be tougher using **Data Augmentation** and visualize its learning progress.\n",
                "5.  **The Final Showdown:** You'll test your new, super-smart model in real-time with an enhanced webcam UI!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1: Setup and Installations\n",
                "\n",
                "First, we need to make sure our environment has all the tools we need. We'll be using TensorFlow (for the model), OpenCV (for image processing), and a few other helpful libraries.\n",
                "\n",
                "Just run the cell below to get everything ready."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "FQT8v6YafvaW"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 1: SETUP AND INSTALLATIONS\n",
                "#\n",
                "\n",
                "# Import all the libraries we'll need\n",
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "import cv2  # This is the OpenCV library\n",
                "from google.colab import files\n",
                "from google.colab.patches import cv2_imshow # for displaying images in Colab\n",
                "import os\n",
                "import zipfile\n",
                "import random\n",
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Imports for the live webcam feed\n",
                "from IPython.display import display, Javascript, HTML\n",
                "from google.colab.output import eval_js\n",
                "from base64 import b64decode, b64encode\n",
                "import io\n",
                "import shutil\n",
                "\n",
                "print(\"âœ… All libraries imported successfully!\")\n",
                "print(f\"Using TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Upload Your Files\n",
                "\n",
                "Now it's time to bring in your hard work from Teachable Machine. You will need to upload several files:\n",
                "\n",
                "1.  **Your Model ZIP:** The converted Keras model zip file. **Important:** Please make sure it is named `model.zip` before uploading.\n",
                "2.  **Your Sample ZIPs:** The zip file of image samples for **each** of your classes. For example, you might have `Class1.zip`, `class2.zip`, `class3.zip`, etc.\n",
                "\n",
                "**Action:** Run the cell below. A \"Choose Files\" button will appear. Select your `model.zip` AND all of your sample class zip files at the same time and upload them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "5e17jAkvf07J"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 2: UPLOAD FILES (MODIFIED FOR MULTIPLE SAMPLE ZIPS)\n",
                "#\n",
                "\n",
                "print(\"Please upload your `model.zip` file and all of your sample class zip files.\")\n",
                "print(\"You can select them all at once in the file dialog.\")\n",
                "\n",
                "# Clean up any previous uploads\n",
                "if os.path.exists('model'):\n",
                "  shutil.rmtree('model')\n",
                "if os.path.exists('samples'):\n",
                "  shutil.rmtree('samples')\n",
                "if os.path.exists('model.zip'):\n",
                "  os.remove('model.zip')\n",
                "\n",
                "# Upload all files\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Separate the model zip from the sample zips\n",
                "if 'model.zip' not in uploaded:\n",
                "    print(\"\\n\\nâŒ ERROR: `model.zip` was not found. Please rename your model zip file and run this cell again.\")\n",
                "else:\n",
                "    model_zip_path = 'model.zip'\n",
                "    sample_zip_paths = [name for name in uploaded.keys() if name != 'model.zip']\n",
                "    print(f\"\\nâœ… Uploaded '{model_zip_path}' successfully.\")\n",
                "    if sample_zip_paths:\n",
                "        print(\"âœ… Uploaded the following sample files:\")\n",
                "        for name in sample_zip_paths:\n",
                "            print(f\"- {name}\")\n",
                "    else:\n",
                "        print(\"âš ï¸ Warning: No sample zip files were uploaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Unzip Everything\n",
                "\n",
                "Our files are uploaded, but they're still zipped up. Let's unpack them.\n",
                "\n",
                "This code is extra smart: it will look at the name of each sample `.zip` file (e.g., `My Face.zip`), create a folder with that name (`My Face/`), and extract the images into it. This makes it work perfectly with the zip files you download directly from Teachable Machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "EGGyrRrnf3zO"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 3: UNZIP FILES (MODIFIED FOR MULTIPLE SAMPLE ZIPS & ROBUSTNESS)\n",
                "#\n",
                "\n",
                "# --- Unzip the model ---\n",
                "print(\"Unzipping the model...\")\n",
                "model_extract_path = 'model'\n",
                "# Clean up previous runs\n",
                "if os.path.exists(model_extract_path):\n",
                "  shutil.rmtree(model_extract_path)\n",
                "os.makedirs(model_extract_path, exist_ok=True)\n",
                "with zipfile.ZipFile(model_zip_path, 'r') as zip_ref:\n",
                "    zip_ref.extractall(model_extract_path)\n",
                "print(\"Model files:\")\n",
                "!ls {model_extract_path}\n",
                "\n",
                "# --- Unzip all the samples ---\n",
                "# This section is modified to be robust to Teachable Machine's zip format.\n",
                "# It will create a sub-folder for each zip file based on the zip file's name.\n",
                "print(\"\\nUnzipping samples into class-specific folders...\")\n",
                "samples_extract_path = 'samples'\n",
                "# Clean up previous runs\n",
                "if os.path.exists(samples_extract_path):\n",
                "  shutil.rmtree(samples_extract_path)\n",
                "os.makedirs(samples_extract_path, exist_ok=True)\n",
                "\n",
                "for sample_zip in sample_zip_paths:\n",
                "    # 1. Get the class name from the zip filename (e.g., \"Class 1.zip\" -> \"Class 1\")\n",
                "    # We use os.path.basename to be safe, then os.path.splitext to remove the extension.\n",
                "    class_name = os.path.splitext(os.path.basename(sample_zip))[0]\n",
                "\n",
                "    # 2. Create a specific directory for this class inside the 'samples' folder\n",
                "    class_dir_path = os.path.join(samples_extract_path, class_name)\n",
                "    os.makedirs(class_dir_path, exist_ok=True)\n",
                "    print(f\"  - Extracting '{sample_zip}' into folder '{class_dir_path}'\")\n",
                "\n",
                "    # 3. Extract the contents of this zip file into its dedicated class folder\n",
                "    with zipfile.ZipFile(sample_zip, 'r') as zip_ref:\n",
                "        zip_ref.extractall(class_dir_path)\n",
                "\n",
                "print(\"\\nSample folders created:\")\n",
                "# Using !ls -R on a variable path in Colab to show directories and some contents\n",
                "!ls -R {samples_extract_path}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4: Load Your Original Model\n",
                "\n",
                "Time to wake up our model! We'll load the `keras_model.h5` file and the `labels.txt` file.\n",
                "\n",
                "You might see errors when loading models from Teachable Machine in a newer version of TensorFlow (like the one in Colab). We add `compile=False` to the `load_model` function. This is a common and important fix for model compatibility!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "5qsB3cMyf5OJ"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 4: LOAD THE ORIGINAL MODEL (WITH FIX)\n",
                "#\n",
                "\n",
                "# --- Load the Keras model ---\n",
                "model_path = 'model/keras_model.h5'\n",
                "labels_path = 'model/labels.txt'\n",
                "\n",
                "# The compile=False is critical for loading models from Teachable Machine\n",
                "original_model = tf.keras.models.load_model(model_path, compile=False)\n",
                "\n",
                "# --- Load the labels ---\n",
                "with open(labels_path, 'r') as f:\n",
                "    # Read lines, strip out the numbering and extra spaces\n",
                "    class_labels = [line.strip().split(' ', 1)[1] for line in f]\n",
                "\n",
                "print(\"ðŸ¤– Model Loaded Successfully!\")\n",
                "print(\"ðŸ§  These are the classes the model knows:\")\n",
                "for i, label in enumerate(class_labels):\n",
                "    print(f\"{i}: {label}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5: Sanity Check - Test the Original Model\n",
                "\n",
                "Does the model remember what you taught it? Let's find out!\n",
                "\n",
                "We'll take a few images from your `samples` folder and see if the model can correctly guess what they are. This is our \"sanity check\" to make sure everything is working as expected. \n",
                "\n",
                "Look at the **confidence bars**. The predictions should be very accurate!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Vyp9ieR4f7DI"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 5: SANITY CHECK\n",
                "#\n",
                "\n",
                "# --- Helper function to show nice confidence bars ---\n",
                "def display_prediction_bars(prediction, labels):\n",
                "    # ANSI escape codes for colors\n",
                "    GREEN = '\\033[92m'\n",
                "    RESET = '\\033[0m'\n",
                "    \n",
                "    top_prediction_index = np.argmax(prediction)\n",
                "    \n",
                "    for i, (label, confidence) in enumerate(zip(labels, prediction[0])):\n",
                "        confidence_percent = confidence * 100\n",
                "        bar = 'â–ˆ' * int(confidence_percent / 4)\n",
                "        if i == top_prediction_index:\n",
                "            print(f'{GREEN}{label:>20}: [{bar:<25}] {confidence_percent:6.2f}%{RESET}')\n",
                "        else:\n",
                "            print(f'{label:>20}: [{bar:<25}] {confidence_percent:6.2f}%')\n",
                "\n",
                "\n",
                "print(\"--- Running Sanity Check on Original Images ---\")\n",
                "\n",
                "# A little helper function to prepare the image for the model\n",
                "def preprocess_image(img_path):\n",
                "    # The model expects images to be 224x224\n",
                "    image = Image.open(img_path).resize((224, 224))\n",
                "    image_array = np.array(image)\n",
                "    # Convert to 3 channels if it's grayscale\n",
                "    if len(image_array.shape) == 2:\n",
                "      image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2RGB)\n",
                "    # Remove alpha channel if it exists\n",
                "    if image_array.shape[2] == 4:\n",
                "      image_array = image_array[:, :, :3]\n",
                "    # Normalize the image\n",
                "    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
                "    # Add a \"batch\" dimension\n",
                "    return np.expand_dims(normalized_image_array, axis=0)\n",
                "\n",
                "# Go through each class folder in your samples\n",
                "samples_dir = 'samples'\n",
                "class_folders = [f for f in os.listdir(samples_dir) if os.path.isdir(os.path.join(samples_dir, f))]\n",
                "\n",
                "for class_name in class_folders:\n",
                "    class_dir = os.path.join(samples_dir, class_name)\n",
                "    \n",
                "    # Pick one random image from the folder\n",
                "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "    if not image_files:\n",
                "        print(f\"\\nNo images found in folder: {class_name}. Skipping.\")\n",
                "        continue\n",
                "\n",
                "    random_image_name = random.choice(image_files)\n",
                "    image_path = os.path.join(class_dir, random_image_name)\n",
                "\n",
                "    # Display the image being tested\n",
                "    print(f\"\\n--- Testing image from folder: {class_name} ---\")\n",
                "    display(Image.open(image_path).resize((150, 150)))\n",
                "\n",
                "    # Preprocess the image and make a prediction\n",
                "    processed_image = preprocess_image(image_path)\n",
                "    prediction = original_model.predict(processed_image, verbose=0)\n",
                "    \n",
                "    # Display the results with bars\n",
                "    print(\"ðŸ¤– Model Prediction:\")\n",
                "    display_prediction_bars(prediction, class_labels)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6: The Break Test! Is Your Model Fragile?\n",
                "\n",
                "Real-world video isn't perfect. Sometimes the lighting is bad (creating \"noise\"), or you might tilt your head (a \"rotation\"). Let's see how our model handles these situations.\n",
                "\n",
                "We will take the same images from before, but this time we'll **add random noise** and **rotate them** a bit before showing them to the model.\n",
                "\n",
                "**Prediction:** Do you think the model will still be accurate? Watch the confidence bars."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "CGHuYopFf8z-"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 6: THE BREAK TEST (NOISE AND ROTATION)\n",
                "#\n",
                "\n",
                "# --- Helper functions to mess up our images ---\n",
                "def add_noise(img):\n",
                "    \"\"\"Adds random 'salt and pepper' noise to an image.\"\"\"\n",
                "    img_array = np.array(img)\n",
                "    rows, cols, _ = img_array.shape\n",
                "    # Add salt\n",
                "    salt_pixels = int(0.05 * img_array.size / 3) # 5% of pixels\n",
                "    for _ in range(salt_pixels):\n",
                "        y, x = random.randint(0, rows - 1), random.randint(0, cols - 1)\n",
                "        img_array[y, x] = (255, 255, 255) # white pixel\n",
                "    # Add pepper\n",
                "    pepper_pixels = int(0.05 * img_array.size / 3)\n",
                "    for _ in range(pepper_pixels):\n",
                "        y, x = random.randint(0, rows - 1), random.randint(0, cols - 1)\n",
                "        img_array[y, x] = (0, 0, 0) # black pixel\n",
                "    return Image.fromarray(img_array)\n",
                "\n",
                "def rotate_image(img):\n",
                "    \"\"\"Rotates an image by a random angle between -25 and 25 degrees.\"\"\"\n",
                "    angle = random.uniform(-25, 25)\n",
                "    return img.rotate(angle, expand=True, fillcolor='black').resize(img.size)\n",
                "\n",
                "\n",
                "# --- The Test ---\n",
                "print(\"--- Running Break Test with NOISE and ROTATION ---\")\n",
                "print(\"Watch how the model's confidence and accuracy might drop!\")\n",
                "\n",
                "# Go through each class folder again\n",
                "for class_name in class_folders:\n",
                "    class_dir = os.path.join(samples_dir, class_name)\n",
                "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "    if not image_files:\n",
                "        continue\n",
                "    random_image_name = random.choice(image_files)\n",
                "    image_path = os.path.join(class_dir, random_image_name)\n",
                "\n",
                "    # Open the image\n",
                "    original_pil_image = Image.open(image_path).convert('RGB')\n",
                "\n",
                "    # Mess it up!\n",
                "    rotated_img = rotate_image(original_pil_image)\n",
                "    noisy_and_rotated_img = add_noise(rotated_img)\n",
                "\n",
                "    # Display the messed up image\n",
                "    print(f\"\\n--- Testing messed up image from folder: {class_name} ---\")\n",
                "    display(noisy_and_rotated_img.resize((150, 150)))\n",
                "\n",
                "    # Preprocess the MESSED UP image for the model\n",
                "    image_array = np.array(noisy_and_rotated_img.resize((224, 224)))\n",
                "    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
                "    processed_image = np.expand_dims(normalized_image_array, axis=0)\n",
                "\n",
                "    # Make a prediction with the original model\n",
                "    prediction = original_model.predict(processed_image, verbose=0)\n",
                "\n",
                "    # Display the results with bars\n",
                "    print(\"ðŸ¤– Model Prediction:\")\n",
                "    display_prediction_bars(prediction, class_labels)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observation:** What happened? Most likely, the model got confused! It wasn't as confident, and it might have even guessed the wrong class. This is because it was only ever trained on \"perfect\" pictures.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7: The Solution! Data Augmentation & Retraining\n",
                "\n",
                "To fix this, we need to teach our model what tilted and noisy images look like. We'll do this by creating a new, bigger dataset. For every *one* image you gave it, we'll create *several* new versions with random rotations and noise. This is called **Data Augmentation**.\n",
                "\n",
                "Then, we'll retrain our model for a short time on this new, tougher dataset. This is like a \"training montage\" in a movie!\n",
                "\n",
                "This part might take a minute or two to run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "nkHMDXl7f-mH"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 7: DATA AUGMENTATION AND RETRAINING\n",
                "#\n",
                "\n",
                "print(\"--- Starting Data Augmentation ---\")\n",
                "print(\"Creating new, tougher training images. This might take a moment...\")\n",
                "\n",
                "X_train = [] # To hold the image data\n",
                "y_train = [] # To hold the labels\n",
                "\n",
                "# Find the class folders and create a mapping from folder name to class index\n",
                "# This is important to ensure the label index matches the one in labels.txt\n",
                "class_name_to_index = {name: i for i, name in enumerate(class_labels)}\n",
                "\n",
                "# Loop through all your original samples\n",
                "for class_folder_name in class_folders:\n",
                "    # Get the correct class index from our mapping\n",
                "    class_index = class_name_to_index.get(class_folder_name.replace('-samples', '').replace('(1)','').replace('(2)','').replace('(3)','').replace('(4)','').strip())\n",
                "    if class_index is None:\n",
                "        # Fallback for simple folder names\n",
                "        class_index = class_name_to_index.get(class_folder_name)\n",
                "        if class_index is None:\n",
                "            print(f\"Warning: Folder '{class_folder_name}' does not match any label in labels.txt. Skipping.\")\n",
                "            continue\n",
                "\n",
                "    print(f\"Augmenting images for class: {class_folder_name} (index: {class_index})\")\n",
                "    class_dir = os.path.join(samples_dir, class_folder_name)\n",
                "    \n",
                "    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "    for image_name in image_files:\n",
                "        image_path = os.path.join(class_dir, image_name)\n",
                "        try:\n",
                "            original_pil_image = Image.open(image_path).convert('RGB')\n",
                "        except Exception as e:\n",
                "            print(f\"Could not open {image_path}, skipping. Error: {e}\")\n",
                "            continue\n",
                "\n",
                "        # Add the original image first\n",
                "        img_array = np.array(original_pil_image.resize((224, 224)))\n",
                "        X_train.append(img_array)\n",
                "        y_train.append(class_index)\n",
                "        \n",
                "        # Now create 5 augmented versions of this image\n",
                "        for _ in range(5):\n",
                "            augmented_img = original_pil_image\n",
                "            # Apply transformations randomly\n",
                "            if random.random() > 0.5:\n",
                "                augmented_img = rotate_image(augmented_img)\n",
                "            if random.random() > 0.5:\n",
                "                augmented_img = add_noise(augmented_img)\n",
                "            \n",
                "            img_array = np.array(augmented_img.resize((224, 224)))\n",
                "            X_train.append(img_array)\n",
                "            y_train.append(class_index)\n",
                "\n",
                "# Convert Python lists to NumPy arrays\n",
                "X_train = np.array(X_train)\n",
                "y_train = np.array(y_train)\n",
                "\n",
                "# Normalize the image data (just like before)\n",
                "X_train = (X_train.astype(np.float32) / 127.5) - 1\n",
                "\n",
                "# Convert labels to a \"one-hot\" format (e.g., class 1 of 3 becomes [0, 1, 0])\n",
                "num_classes = len(class_labels)\n",
                "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
                "\n",
                "print(f\"\\nOriginal dataset had ~{len(X_train)//6} images.\")\n",
                "print(f\"New augmented dataset has {len(X_train)} images!\")\n",
                "print(\"\\n--- Now Retraining the Model ---\")\n",
                "\n",
                "# We need to \"compile\" the model to get it ready for training.\n",
                "# We'll use a standard \"Adam\" optimizer and \"Categorical Crossentropy\" for the loss function.\n",
                "original_model.compile(optimizer='adam',\n",
                "                       loss='categorical_crossentropy',\n",
                "                       metrics=['accuracy'])\n",
                "\n",
                "# Let's train! An \"epoch\" is one full pass through the dataset.\n",
                "# We'll do a few epochs.\n",
                "history = original_model.fit(X_train, y_train_one_hot, epochs=5, batch_size=32, shuffle=True, validation_split=0.1)\n",
                "\n",
                "# Let's rename our newly trained model\n",
                "robust_model = original_model\n",
                "print(\"\\nâœ… Training complete! Your model is now more robust!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing the Training Process\n",
                "\n",
                "How do we know the model actually learned? We can plot its **accuracy** and **loss** from the training process. \n",
                "- **Accuracy** should go **UP** (we want it to be more correct).\n",
                "- **Loss** (which is like \"error\") should go **DOWN** (we want it to make fewer mistakes).\n",
                "\n",
                "The graphs below show that our model got better with each pass (epoch) through our new, tougher, augmented dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "qR7h5U9_mYcM"
            },
            "outputs": [],
            "source": [
                "# Plotting the training history\n",
                "plt.figure(figsize=(12, 4))\n",
                "\n",
                "# Plot Training & Validation Accuracy\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
                "plt.title('Training and Validation Accuracy')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "\n",
                "# Plot Training & Validation Loss\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Training Loss')\n",
                "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
                "plt.title('Training and Validation Loss')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 8: The Final Showdown! Live Webcam Test\n",
                "\n",
                "This is the moment of truth. Let's test our new **robust model** with a live webcam feed and our new, beautiful UI.\n",
                "\n",
                "**Action:**\n",
                "1.  Run the cell below.\n",
                "2.  A video feed of your webcam will appear. You must **Allow** your browser to use the camera.\n",
                "3.  Try moving your head, tilting it, and making different faces. The model should be much better at recognizing you and your neighbors, even when the image isn't perfect!\n",
                "4.  To stop the feed, **click on the video frame itself**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "pDtF3WM1gAZF"
            },
            "outputs": [],
            "source": [
                "#\n",
                "# STEP 8: LIVE WEBCAM TEST (ENHANCED UI)\n",
                "#\n",
                "\n",
                "# --- Helper functions to handle the webcam stream and UI ---\n",
                "\n",
                "def video_stream():\n",
                "  js = Javascript('''\n",
                "    var video;\n",
                "    var div = null;\n",
                "    var stream;\n",
                "    var captureCanvas;\n",
                "    var predictionContainer;\n",
                "\n",
                "    var pendingResolve = null;\n",
                "    var shutdown = false;\n",
                "\n",
                "    function removeDom() {\n",
                "      stream.getTracks().forEach(function(track) {\n",
                "        track.stop();\n",
                "      });\n",
                "      video.remove();\n",
                "      div.remove();\n",
                "      video = null;\n",
                "      div = null;\n",
                "      stream = null;\n",
                "      captureCanvas = null;\n",
                "      predictionContainer = null;\n",
                "    }\n",
                "\n",
                "    function onAnimationFrame() {\n",
                "      if (!shutdown) {\n",
                "        window.requestAnimationFrame(onAnimationFrame);\n",
                "      }\n",
                "      if (pendingResolve) {\n",
                "        var result = \"\";\n",
                "        if (!shutdown) {\n",
                "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
                "          result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
                "        }\n",
                "        var lp = pendingResolve;\n",
                "        pendingResolve = null;\n",
                "        lp(result);\n",
                "      }\n",
                "    }\n",
                "\n",
                "    async function createDom() {\n",
                "      if (div !== null) {\n",
                "        return;\n",
                "      }\n",
                "      div = document.createElement('div');\n",
                "      div.style.border = '2px solid black';\n",
                "      div.style.padding = '3px';\n",
                "      div.style.width = '100%';\n",
                "      div.style.maxWidth = '600px';\n",
                "      document.body.appendChild(div);\n",
                "\n",
                "      video = document.createElement('video');\n",
                "      video.style.display = 'block';\n",
                "      video.width = div.clientWidth - 6;\n",
                "      video.setAttribute('playsinline', '');\n",
                "      video.onclick = () => { shutdown = true; };\n",
                "      stream = await navigator.mediaDevices.getUserMedia(\n",
                "          {video: { facingMode: \"user\" }});\n",
                "      div.appendChild(video);\n",
                "\n",
                "      const instruction = document.createElement('div');\n",
                "      instruction.innerHTML = \"<b>Click on the video frame to stop</b>\";\n",
                "      instruction.style.textAlign = 'center';\n",
                "      instruction.style.padding = '5px';\n",
                "      div.appendChild(instruction);\n",
                "\n",
                "      // Create the container for prediction bars\n",
                "      predictionContainer = document.createElement('div');\n",
                "      div.appendChild(predictionContainer);\n",
                "      \n",
                "      // Add some CSS for the progress bars\n",
                "      const style = document.createElement('style');\n",
                "      style.innerHTML = `\n",
                "        .prediction-bar-container {\n",
                "          display: flex;\n",
                "          align-items: center;\n",
                "          margin-bottom: 5px;\n",
                "        }\n",
                "        .prediction-label {\n",
                "          width: 150px; \n",
                "          text-align: right;\n",
                "          margin-right: 10px;\n",
                "          font-family: sans-serif;\n",
                "          font-size: 14px;\n",
                "        }\n",
                "        .progress-bar-bg {\n",
                "          flex-grow: 1;\n",
                "          height: 20px;\n",
                "          background-color: #e0e0e0;\n",
                "          border-radius: 5px;\n",
                "          overflow: hidden;\n",
                "        }\n",
                "        .progress-bar {\n",
                "          height: 100%;\n",
                "          background-color: #757575; /* Gray for non-winners */\n",
                "          transition: width 0.2s ease-in-out;\n",
                "          border-radius: 5px;\n",
                "        }\n",
                "        .progress-bar.winner {\n",
                "          background-color: #4CAF50; /* Green for the winner */\n",
                "        }\n",
                "      `;\n",
                "      document.head.appendChild(style);\n",
                "\n",
                "      video.srcObject = stream;\n",
                "      await video.play();\n",
                "\n",
                "      captureCanvas = document.createElement('canvas');\n",
                "      captureCanvas.width = 640;\n",
                "      captureCanvas.height = 480;\n",
                "      window.requestAnimationFrame(onAnimationFrame);\n",
                "    }\n",
                "\n",
                "    async function updatePrediction(predictionHtml) {\n",
                "      if (shutdown) {\n",
                "        removeDom();\n",
                "        shutdown = false;\n",
                "        return '';\n",
                "      }\n",
                "      await createDom();\n",
                "      predictionContainer.innerHTML = predictionHtml;\n",
                "      var result = await new Promise(function(resolve, reject) {\n",
                "        pendingResolve = resolve;\n",
                "      });\n",
                "      shutdown = false;\n",
                "      return result;\n",
                "    }\n",
                "    ''')\n",
                "\n",
                "  display(js)\n",
                "\n",
                "def get_frame(prediction_html):\n",
                "  # This is the corrected function call to the new JS function\n",
                "  data = eval_js('updatePrediction(\"{}\")'.format(prediction_html.replace('\"', '\\\"')))\n",
                "  return data\n",
                "\n",
                "def js_to_image(js_reply):\n",
                "  \"\"\"Decodes a base64-encoded image from JavaScript into an OpenCV image.\"\"\"\n",
                "  image_bytes = b64decode(js_reply.split(',')[1])\n",
                "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
                "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
                "  return img\n",
                "\n",
                "def create_html_bars(prediction, labels):\n",
                "    \"\"\"Creates an HTML string with progress bars for the predictions.\"\"\"\n",
                "    html = \"\"\n",
                "    top_prediction_index = np.argmax(prediction[0])\n",
                "    \n",
                "    for i, (label, confidence) in enumerate(zip(labels, prediction[0])):\n",
                "        confidence_percent = confidence * 100\n",
                "        winner_class = 'winner' if i == top_prediction_index else ''\n",
                "        html += f'''\n",
                "        <div class=\"prediction-bar-container\">\n",
                "          <div class=\"prediction-label\">{label}</div>\n",
                "          <div class=\"progress-bar-bg\">\n",
                "            <div class=\"progress-bar {winner_class}\" style=\"width: {confidence_percent}%;\"></div>\n",
                "          </div>\n",
                "          <div style=\"margin-left: 10px; font-family: sans-serif; font-size: 14px;\">{confidence_percent:.1f}%</div>\n",
                "        </div>\n",
                "        '''\n",
                "    return html\n",
                "\n",
                "# --- THE MAIN LOOP ---\n",
                "print(\"Starting live webcam feed... Allow camera access when prompted.\")\n",
                "video_stream()\n",
                "\n",
                "prediction_html = \"Capturing...\"\n",
                "while True:\n",
                "    js_reply = get_frame(prediction_html)\n",
                "    if not js_reply:\n",
                "        break\n",
                "\n",
                "    # Convert the frame to an OpenCV image\n",
                "    frame = js_to_image(js_reply)\n",
                "\n",
                "    # Preprocess the frame for our model\n",
                "    resized_frame = cv2.resize(frame, (224, 224))\n",
                "    normalized_frame = (resized_frame.astype(np.float32) / 127.5) - 1\n",
                "    input_frame = np.expand_dims(normalized_frame, axis=0)\n",
                "\n",
                "    # Make a prediction with our NEW ROBUST model\n",
                "    prediction = robust_model.predict(input_frame, verbose=0) \n",
                "\n",
                "    # Create the HTML for the prediction bars\n",
                "    prediction_html = create_html_bars(prediction, class_labels)\n",
                "\n",
                "print(\"Webcam feed stopped.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ‰ Congratulations! ðŸŽ‰\n",
                "\n",
                "You have successfully:\n",
                "- Loaded a pre-trained model and fixed compatibility issues.\n",
                "- Handled a flexible file structure for your data.\n",
                "- Identified the model's weaknesses using real-world variations (noise and rotation).\n",
                "- Fixed those weaknesses by **augmenting your data**.\n",
                "- **Retrained** your model to make it more robust.\n",
                "- Visualized the model's training improvement with graphs.\n",
                "- Tested your new and improved model in real-time with a cool UI!\n",
                "\n",
                "This is a fundamental workflow in Computer Vision and Machine Learning. Well done!"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
